{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75069842",
   "metadata": {},
   "source": [
    "Jesus Rodrigo Colina Nunez\n",
    "\n",
    "Student Number: 2017156 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbd3d4",
   "metadata": {},
   "source": [
    "CA 2 Semester 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa06a25",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee86c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, to_timestamp, date_format, length\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8341ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "##spark.conf.set(\"spark.sql.debug.maxToStringFields\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1030c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8986866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ProjectTweets.csv')\n",
    "\n",
    "#Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff8a538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  5  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()\n",
    "\n",
    "# here I show how it looks, HERE I am not using Pyspark just yet\n",
    "# Here I am using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bce637",
   "metadata": {},
   "source": [
    "## Load data set into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99ed975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').option('header', 'false').load('/user1/ProjectTweets.csv')\n",
    "\n",
    "#I load the data set into Pyspak in order to read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29760b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#More imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e8544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.show()\n",
    "\n",
    "#Here I show the data set and we see that it does not have columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3474bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "\n",
    "#Inspect the DataFrame's Structure:  It reveals the blueprint of my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046c0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"index\", \"id\", \"timestamp\", \"query\", \"username\", \"tweet\"]\n",
    "for i in range(len(df.columns)):\n",
    "    df = df.withColumnRenamed(\"_c\" + str(i), columns[i])\n",
    "    \n",
    "#I am going to change the name of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3370c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 2. Save as CSV\n",
    "df.write.csv(\"Home/Downloads/CA2_Semestre2/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff2a4061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "# This schema provides a valuable overview for understanding the structure and content of my dataset \n",
    "# before I start analyzing or manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca9b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|index|id        |timestamp                   |query   |username       |tweet                                                                                                              |\n",
      "+-----+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|1    |1467810672|Mon Apr 06 22:19:49 PDT 2009|NO_QUERY|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|2    |1467810917|Mon Apr 06 22:19:53 PDT 2009|NO_QUERY|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|3    |1467811184|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|ElleCTF        |my whole body feels itchy and like its on fire                                                                     |\n",
      "|4    |1467811193|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "|5    |1467811372|Mon Apr 06 22:20:00 PDT 2009|NO_QUERY|joy_wolf       |@Kwesidei not the whole crew                                                                                       |\n",
      "|6    |1467811592|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|mybirch        |Need a hug                                                                                                         |\n",
      "|7    |1467811594|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|coZZ           |@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                |\n",
      "|8    |1467811795|Mon Apr 06 22:20:05 PDT 2009|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope they didn't have it                                                                                |\n",
      "|9    |1467812025|Mon Apr 06 22:20:09 PDT 2009|NO_QUERY|mimismo        |@twittera que me muera ?                                                                                           |\n",
      "+-----+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)\n",
    "\n",
    "#Here I show the 10 first rows and we noticed that the names has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944a47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 20:37:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 3:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+--------+--------------------+--------------------+\n",
      "|summary|             index|                  id|           timestamp|   query|            username|               tweet|\n",
      "+-------+------------------+--------------------+--------------------+--------+--------------------+--------------------+\n",
      "|  count|           1600000|             1600000|             1600000| 1600000|             1600000|             1600000|\n",
      "|   mean|          799999.5|1.9988175522956276E9|                null|    null| 4.325887521835714E9|                null|\n",
      "| stddev|461880.35968924535|1.9357607362268043E8|                null|    null|5.162733218454890...|                null|\n",
      "|    min|                 0|          1467810369|Fri Apr 17 20:30:...|NO_QUERY|        000catnap000|                 ...|\n",
      "|    max|            999999|          2329205794|Wed May 27 07:27:...|NO_QUERY|          zzzzeus111|ï¿½ï¿½ï¿½ï¿½ï¿½ß§...|\n",
      "+-------+------------------+--------------------+--------------------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get summary statistics count, mean\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dc835",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ff2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     tweet_length|\n",
      "+-------+-----------------+\n",
      "|  count|          1600000|\n",
      "|   mean|     74.090110625|\n",
      "| stddev|36.44113790653486|\n",
      "|    min|                6|\n",
      "|    max|              374|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add a column for tweet length\n",
    "df = df.withColumn(\"tweet_length\", length(col(\"tweet\")))\n",
    "\n",
    "# Analyze tweet lengths (min, max, mean)\n",
    "df.describe(\"tweet_length\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d90dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 22:18:05 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create or get SparkSession \n",
    "spark = SparkSession.builder.appName(\"TwitterSentimentEDA\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1de9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-------+--------+-------+------------+------------+\n",
      "|  index|     id|timestamp|  query|username|  tweet|tweet_length|timestamp_dt|\n",
      "+-------+-------+---------+-------+--------+-------+------------+------------+\n",
      "|1600000|1600000|  1600000|1600000| 1600000|1600000|     1600000|     1600000|\n",
      "+-------+-------+---------+-------+--------+-------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:===================================================>       (7 + 1) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Missing Values\n",
    "print(\"\\nMissing Values:\")\n",
    "df.select([(count(col(c).isNull())).alias(c) for c in df.columns]).show()\n",
    "\n",
    "\n",
    "#There is no missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a940a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to proper datetime format\n",
    "df = df.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"EEE MMM dd HH:mm:ss zzz yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49b8770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date and time components for later analysis\n",
    "df = df.withColumn(\"date\", date_format(col(\"timestamp\"), \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"time\", date_format(col(\"timestamp\"), \"HH:mm:ss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1f2c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|               tweet|tweet_length|\n",
      "+--------------------+------------+\n",
      "|@switchfoot http:...|         115|\n",
      "|is upset that he ...|         111|\n",
      "|@Kenichan I dived...|          89|\n",
      "|my whole body fee...|          47|\n",
      "|@nationwideclass ...|         111|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze tweet length\n",
    "df = df.withColumn(\"tweet_length\", length(col(\"tweet\")))\n",
    "df.select(\"tweet\", \"tweet_length\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36b3cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "\n",
    "df = df.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8c28098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      date| count|\n",
      "+----------+------+\n",
      "|2009-04-18| 16132|\n",
      "|2009-05-04| 29823|\n",
      "|2009-05-27| 11619|\n",
      "|2009-04-19| 33670|\n",
      "|2009-05-25|   169|\n",
      "|2009-05-29| 55874|\n",
      "|2009-04-20| 18447|\n",
      "|2009-04-07| 20671|\n",
      "|2009-04-21| 11105|\n",
      "|2009-05-22| 41206|\n",
      "|2009-05-03| 25045|\n",
      "|2009-05-11|  6217|\n",
      "|2009-05-30|103990|\n",
      "|2009-05-14| 21526|\n",
      "|2009-05-12|  4186|\n",
      "|2009-05-10| 31551|\n",
      "|2009-05-24|   169|\n",
      "|2009-05-02| 31096|\n",
      "|2009-05-18| 44564|\n",
      "|2009-05-17| 41205|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by date and count tweets per day\n",
    "tweets_per_day = df.groupBy(\"date\").count()\n",
    "tweets_per_day.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "046a4fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|       username|count|\n",
      "+---------------+-----+\n",
      "|       lost_dog|  549|\n",
      "|        webwoke|  345|\n",
      "|       tweetpet|  310|\n",
      "|SallytheShizzle|  281|\n",
      "|    VioletsCRUK|  279|\n",
      "|    mcraddictal|  276|\n",
      "|       tsarnick|  248|\n",
      "|    what_bugs_u|  246|\n",
      "|    Karen230683|  238|\n",
      "|      DarkPiano|  236|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by username and count tweets per user (top 10)\n",
    "tweets_per_user = df.groupBy(\"username\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "tweets_per_user.show()\n",
    "#The people that habe most tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503959a",
   "metadata": {},
   "source": [
    "## NLTK vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2b13170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (1.4.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m209.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m114.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m143.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.5.15 tqdm-4.66.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbbd100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8ad35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Function to clean tweets\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)  # Remove URLs\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)     # Remove mentions\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)     # Remove hashtags\n",
    "    tweet = re.sub(r'[^A-Za-z\\s]', '', tweet)  # Remove special characters\n",
    "    tweet = tweet.lower()                  # Convert to lowercase\n",
    "    tweet = tweet.strip()                  # Remove leading/trailing whitespace\n",
    "    return tweet\n",
    "\n",
    "# Register UDF\n",
    "clean_tweet_udf = udf(lambda x: clean_tweet(x), StringType())\n",
    "\n",
    "# Apply UDF to the DataFrame\n",
    "df_cleaned = df.withColumn('cleaned_tweet', clean_tweet_udf(df['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1687fd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hduser/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment\n",
    "def get_sentiment(tweet):\n",
    "    scores = sid.polarity_scores(tweet)\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Register UDF\n",
    "get_sentiment_udf = udf(lambda x: get_sentiment(x), StringType())\n",
    "\n",
    "# Apply UDF to the DataFrame\n",
    "df_sentiment = df_cleaned.withColumn('sentiment', get_sentiment_udf(df_cleaned['cleaned_tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde3505d",
   "metadata": {},
   "source": [
    "## Total result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9bc965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df_pandas = df_sentiment.select('sentiment').toPandas()\n",
    "\n",
    "# Plot the sentiment distribution\n",
    "sentiment_counts = df_pandas['sentiment'].value_counts()\n",
    "sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n",
    "plt.title('Sentiment Analysis of Tweets')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd7d0e",
   "metadata": {},
   "source": [
    "## BY week and HOur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f36c62da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+----+---------+\n",
      "|          timestamp|day_of_week|hour|sentiment|\n",
      "+-------------------+-----------+----+---------+\n",
      "|2009-04-07 06:19:45|        Tue|   6| negative|\n",
      "|2009-04-07 06:19:49|        Tue|   6| negative|\n",
      "|2009-04-07 06:19:53|        Tue|   6| positive|\n",
      "|2009-04-07 06:19:57|        Tue|   6| negative|\n",
      "|2009-04-07 06:19:57|        Tue|   6| negative|\n",
      "|2009-04-07 06:20:00|        Tue|   6|  neutral|\n",
      "|2009-04-07 06:20:03|        Tue|   6| positive|\n",
      "|2009-04-07 06:20:03|        Tue|   6| positive|\n",
      "|2009-04-07 06:20:05|        Tue|   6|  neutral|\n",
      "|2009-04-07 06:20:09|        Tue|   6|  neutral|\n",
      "|2009-04-07 06:20:16|        Tue|   6|  neutral|\n",
      "|2009-04-07 06:20:17|        Tue|   6|  neutral|\n",
      "|2009-04-07 06:20:19|        Tue|   6| negative|\n",
      "|2009-04-07 06:20:19|        Tue|   6| negative|\n",
      "|2009-04-07 06:20:20|        Tue|   6| positive|\n",
      "|2009-04-07 06:20:20|        Tue|   6| positive|\n",
      "|2009-04-07 06:20:22|        Tue|   6| negative|\n",
      "|2009-04-07 06:20:25|        Tue|   6|  neutral|\n",
      "|2009-04-07 06:20:31|        Tue|   6| positive|\n",
      "|2009-04-07 06:20:34|        Tue|   6| positive|\n",
      "+-------------------+-----------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, date_format\n",
    "\n",
    "# Convert the timestamp to a Spark DateType and extract day of the week and hour\n",
    "df_with_date = df_sentiment.withColumn('date', to_date('timestamp', 'E MMM dd HH:mm:ss Z yyyy'))\n",
    "df_with_day = df_with_date.withColumn('day_of_week', date_format('date', 'E'))\n",
    "df_with_hour = df_with_day.withColumn('hour', date_format('timestamp', 'H'))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_with_hour.select('timestamp', 'day_of_week', 'hour', 'sentiment').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176518d",
   "metadata": {},
   "source": [
    "## By day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "853a8e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "df_pandas_day = df_with_hour.select('day_of_week', 'sentiment').toPandas()\n",
    "\n",
    "# Plot sentiment distribution by day of the week\n",
    "sentiment_by_day = df_pandas_day.groupby(['day_of_week', 'sentiment']).size().unstack()\n",
    "sentiment_by_day.plot(kind='bar', stacked=True, color=['green', 'red', 'blue'])\n",
    "plt.title('Sentiment Distribution by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7089b",
   "metadata": {},
   "source": [
    "### ARIMA, SARIMA AND RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00a297c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, avg\n",
    "\n",
    "# Convert sentiment to numerical scores\n",
    "df_with_scores = df_with_hour.withColumn('sentiment_score', \n",
    "                                         when(df_with_hour.sentiment == 'positive', 1).\n",
    "                                         when(df_with_hour.sentiment == 'negative', -1).\n",
    "                                         otherwise(0))\n",
    "\n",
    "# Aggregate sentiment scores by day\n",
    "df_daily_sentiment = df_with_scores.groupBy('date').agg(avg('sentiment_score').alias('average_sentiment'))\n",
    "\n",
    "# Convert to Pandas DataFrame for time series analysis\n",
    "df_daily_sentiment_pd = df_daily_sentiment.orderBy('date').toPandas()\n",
    "\n",
    "# Set the date as the index\n",
    "df_daily_sentiment_pd.set_index('date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "841cdc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/hduser/.local/lib/python3.10/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/lib/python3/dist-packages (from statsmodels) (1.8.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/hduser/.local/lib/python3.10/site-packages (from statsmodels) (2.2.1)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hduser/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.2\n"
     ]
    }
   ],
   "source": [
    "##!pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12967ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "print(statsmodels.__version__)  # This ptins the installed version, just to check that it is intalled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db961483",
   "metadata": {},
   "source": [
    "## ARIMA AND SARIMA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9dd4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      " This problem is unconstrained.\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.13238D-01    |proj g|=  4.20333D+00\n",
      "\n",
      "At iterate    5    f= -9.08786D-01    |proj g|=  3.84733D-01\n",
      "\n",
      "At iterate   10    f= -9.10687D-01    |proj g|=  6.48310D-01\n",
      "\n",
      "At iterate   15    f= -9.19997D-01    |proj g|=  8.09425D-01\n",
      "\n",
      "At iterate   20    f= -9.97457D-01    |proj g|=  4.66075D-01\n",
      "\n",
      "At iterate   25    f= -1.00763D+00    |proj g|=  2.74343D-01\n",
      "\n",
      "At iterate   30    f= -1.00951D+00    |proj g|=  1.15718D-01\n",
      "\n",
      "At iterate   35    f= -1.00969D+00    |proj g|=  7.11851D-02\n",
      "\n",
      "At iterate   40    f= -1.00976D+00    |proj g|=  5.01727D-03\n",
      "\n",
      "At iterate   45    f= -1.00979D+00    |proj g|=  2.46508D-03\n",
      "\n",
      "At iterate   50    f= -1.00979D+00    |proj g|=  1.54197D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     74      1     0     0   1.542D-02  -1.010D+00\n",
      "  F =  -1.0097945800761383     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit ARIMA model\n",
    "arima_model = sm.tsa.ARIMA(df_daily_sentiment_pd['average_sentiment'], order=(1, 1, 1))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "# Fit SARIMA model\n",
    "sarima_model = SARIMAX(df_daily_sentiment_pd['average_sentiment'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 7))\n",
    "sarima_result = sarima_model.fit()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_daily_sentiment_pd['average_sentiment'], label='Observed')\n",
    "plt.plot(arima_result.predict(start=0, end=len(df_daily_sentiment_pd)-1), label='ARIMA Predicted')\n",
    "plt.plot(sarima_result.predict(start=0, end=len(df_daily_sentiment_pd)-1), label='SARIMA Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65de20f",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3be1d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare data for RNN\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 7\n",
    "data = df_daily_sentiment_pd['average_sentiment'].values\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Define RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X, verbose=0)\n",
    "\n",
    "# Convert index to list and slice appropriately for plotting\n",
    "index = df_daily_sentiment_pd.index[seq_length:].tolist()\n",
    "\n",
    "# Plot the results for RNN\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(index, y, label='Observed')\n",
    "plt.plot(index, y_pred, label='RNN Predicted')\n",
    "plt.legend()\n",
    "plt.title('RNN Model Predictions vs Observed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Sentiment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcf5e34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(df_daily_sentiment_pd['average_sentiment'], label='Observed', marker='o', linestyle='-')\n",
    "\n",
    "# Plot ARIMA and SARIMA predictions directly on the index (not shifted)\n",
    "plt.plot(arima_result.predict(start=0, end=len(df_daily_sentiment_pd)-1), label='ARIMA Predicted', linestyle='dashed')\n",
    "plt.plot(sarima_result.predict(start=0, end=len(df_daily_sentiment_pd)-1), label='SARIMA Predicted', linestyle='dotted')\n",
    "\n",
    "# Plot RNN predictions on the correct sliced index\n",
    "plt.plot(index, y_pred, label='RNN Predicted', linestyle='dashdot') \n",
    "\n",
    "plt.legend()\n",
    "plt.title('Observed vs. Predicted Sentiment (ARIMA, SARIMA, RNN)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Sentiment')\n",
    "plt.grid(axis='y', linestyle='--')  \n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "014e0b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observed</th>\n",
       "      <th>ARIMA Predicted</th>\n",
       "      <th>SARIMA Predicted</th>\n",
       "      <th>RNN Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-05-04</th>\n",
       "      <td>0.238239</td>\n",
       "      <td>0.255963</td>\n",
       "      <td>0.371043</td>\n",
       "      <td>0.234376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-10</th>\n",
       "      <td>0.293652</td>\n",
       "      <td>0.237337</td>\n",
       "      <td>0.276328</td>\n",
       "      <td>0.229559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-11</th>\n",
       "      <td>0.265562</td>\n",
       "      <td>0.296186</td>\n",
       "      <td>0.296631</td>\n",
       "      <td>0.242361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-12</th>\n",
       "      <td>0.233636</td>\n",
       "      <td>0.264692</td>\n",
       "      <td>0.245831</td>\n",
       "      <td>0.244205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-14</th>\n",
       "      <td>0.233253</td>\n",
       "      <td>0.231898</td>\n",
       "      <td>0.232480</td>\n",
       "      <td>0.233723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-17</th>\n",
       "      <td>0.277442</td>\n",
       "      <td>0.232887</td>\n",
       "      <td>0.242952</td>\n",
       "      <td>0.223655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-18</th>\n",
       "      <td>0.289449</td>\n",
       "      <td>0.279534</td>\n",
       "      <td>0.274083</td>\n",
       "      <td>0.230361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-22</th>\n",
       "      <td>0.290322</td>\n",
       "      <td>0.290455</td>\n",
       "      <td>0.271787</td>\n",
       "      <td>0.245943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-24</th>\n",
       "      <td>0.301775</td>\n",
       "      <td>0.290565</td>\n",
       "      <td>0.336687</td>\n",
       "      <td>0.260149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-25</th>\n",
       "      <td>0.284024</td>\n",
       "      <td>0.302385</td>\n",
       "      <td>0.289193</td>\n",
       "      <td>0.267946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-27</th>\n",
       "      <td>0.236939</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.259179</td>\n",
       "      <td>0.268325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-29</th>\n",
       "      <td>0.273866</td>\n",
       "      <td>0.234484</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.252785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-30</th>\n",
       "      <td>0.279056</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>0.300447</td>\n",
       "      <td>0.252892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-31</th>\n",
       "      <td>0.275931</td>\n",
       "      <td>0.279573</td>\n",
       "      <td>0.281262</td>\n",
       "      <td>0.254215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-01</th>\n",
       "      <td>0.255857</td>\n",
       "      <td>0.275881</td>\n",
       "      <td>0.266418</td>\n",
       "      <td>0.259098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-02</th>\n",
       "      <td>0.255007</td>\n",
       "      <td>0.254864</td>\n",
       "      <td>0.293485</td>\n",
       "      <td>0.251227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-03</th>\n",
       "      <td>0.245915</td>\n",
       "      <td>0.254767</td>\n",
       "      <td>0.239022</td>\n",
       "      <td>0.242894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-04</th>\n",
       "      <td>0.207633</td>\n",
       "      <td>0.245422</td>\n",
       "      <td>0.214988</td>\n",
       "      <td>0.234552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-05</th>\n",
       "      <td>0.248467</td>\n",
       "      <td>0.205659</td>\n",
       "      <td>0.216505</td>\n",
       "      <td>0.216498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-06</th>\n",
       "      <td>0.272082</td>\n",
       "      <td>0.250073</td>\n",
       "      <td>0.271498</td>\n",
       "      <td>0.213821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-07</th>\n",
       "      <td>0.265307</td>\n",
       "      <td>0.273560</td>\n",
       "      <td>0.274368</td>\n",
       "      <td>0.221923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-08</th>\n",
       "      <td>0.235038</td>\n",
       "      <td>0.265270</td>\n",
       "      <td>0.254016</td>\n",
       "      <td>0.229806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-14</th>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.233548</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.226276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-15</th>\n",
       "      <td>0.240857</td>\n",
       "      <td>0.311276</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>0.245401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-16</th>\n",
       "      <td>0.198297</td>\n",
       "      <td>0.238223</td>\n",
       "      <td>0.205094</td>\n",
       "      <td>0.236427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-17</th>\n",
       "      <td>-0.127832</td>\n",
       "      <td>0.195686</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.215298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-18</th>\n",
       "      <td>-0.125373</td>\n",
       "      <td>-0.144328</td>\n",
       "      <td>-0.119080</td>\n",
       "      <td>0.069572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-19</th>\n",
       "      <td>-0.116198</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.125462</td>\n",
       "      <td>-0.049866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-20</th>\n",
       "      <td>-0.119567</td>\n",
       "      <td>-0.116382</td>\n",
       "      <td>-0.131037</td>\n",
       "      <td>-0.118775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-21</th>\n",
       "      <td>-0.095283</td>\n",
       "      <td>-0.119769</td>\n",
       "      <td>-0.088207</td>\n",
       "      <td>-0.149887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-22</th>\n",
       "      <td>-0.126728</td>\n",
       "      <td>-0.094134</td>\n",
       "      <td>-0.115064</td>\n",
       "      <td>-0.148457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-23</th>\n",
       "      <td>-0.140698</td>\n",
       "      <td>-0.128039</td>\n",
       "      <td>-0.162430</td>\n",
       "      <td>-0.139282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-24</th>\n",
       "      <td>-0.132445</td>\n",
       "      <td>-0.141644</td>\n",
       "      <td>-0.159236</td>\n",
       "      <td>-0.126865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-25</th>\n",
       "      <td>-0.132305</td>\n",
       "      <td>-0.132230</td>\n",
       "      <td>-0.112684</td>\n",
       "      <td>-0.128563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Observed  ARIMA Predicted  SARIMA Predicted  RNN Predicted\n",
       "date                                                                  \n",
       "2009-05-04  0.238239         0.255963          0.371043       0.234376\n",
       "2009-05-10  0.293652         0.237337          0.276328       0.229559\n",
       "2009-05-11  0.265562         0.296186          0.296631       0.242361\n",
       "2009-05-12  0.233636         0.264692          0.245831       0.244205\n",
       "2009-05-14  0.233253         0.231898          0.232480       0.233723\n",
       "2009-05-17  0.277442         0.232887          0.242952       0.223655\n",
       "2009-05-18  0.289449         0.279534          0.274083       0.230361\n",
       "2009-05-22  0.290322         0.290455          0.271787       0.245943\n",
       "2009-05-24  0.301775         0.290565          0.336687       0.260149\n",
       "2009-05-25  0.284024         0.302385          0.289193       0.267946\n",
       "2009-05-27  0.236939         0.283276          0.259179       0.268325\n",
       "2009-05-29  0.273866         0.234484          0.235600       0.252785\n",
       "2009-05-30  0.279056         0.275185          0.300447       0.252892\n",
       "2009-05-31  0.275931         0.279573          0.281262       0.254215\n",
       "2009-06-01  0.255857         0.275881          0.266418       0.259098\n",
       "2009-06-02  0.255007         0.254864          0.293485       0.251227\n",
       "2009-06-03  0.245915         0.254767          0.239022       0.242894\n",
       "2009-06-04  0.207633         0.245422          0.214988       0.234552\n",
       "2009-06-05  0.248467         0.205659          0.216505       0.216498\n",
       "2009-06-06  0.272082         0.250073          0.271498       0.213821\n",
       "2009-06-07  0.265307         0.273560          0.274368       0.221923\n",
       "2009-06-08  0.235038         0.265270          0.254016       0.229806\n",
       "2009-06-14  0.308000         0.233548          0.263341       0.226276\n",
       "2009-06-15  0.240857         0.311276          0.295501       0.245401\n",
       "2009-06-16  0.198297         0.238223          0.205094       0.236427\n",
       "2009-06-17 -0.127832         0.195686          0.215153       0.215298\n",
       "2009-06-18 -0.125373        -0.144328         -0.119080       0.069572\n",
       "2009-06-19 -0.116198        -0.128546         -0.125462      -0.049866\n",
       "2009-06-20 -0.119567        -0.116382         -0.131037      -0.118775\n",
       "2009-06-21 -0.095283        -0.119769         -0.088207      -0.149887\n",
       "2009-06-22 -0.126728        -0.094134         -0.115064      -0.148457\n",
       "2009-06-23 -0.140698        -0.128039         -0.162430      -0.139282\n",
       "2009-06-24 -0.132445        -0.141644         -0.159236      -0.126865\n",
       "2009-06-25 -0.132305        -0.132230         -0.112684      -0.128563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a new DataFrame to hold results\n",
    "results_df = pd.DataFrame({\n",
    "    'Observed': df_daily_sentiment_pd['average_sentiment'],\n",
    "    'ARIMA Predicted': arima_result.predict(start=0, end=len(df_daily_sentiment_pd)-1),\n",
    "    'SARIMA Predicted': sarima_result.predict(start=0, end=len(df_daily_sentiment_pd)-1)\n",
    "})\n",
    "\n",
    "# Add RNN predictions to the sliced index\n",
    "results_df = results_df.iloc[seq_length:]  \n",
    "results_df['RNN Predicted'] = y_pred.flatten() \n",
    "\n",
    "# Display the results in a nicely formatted table within the notebook\n",
    "display(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46d0777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/hduser/.local/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /home/hduser/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Requirement already satisfied: seaborn in /home/hduser/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: statsmodels in /home/hduser/.local/lib/python3.10/site-packages (0.14.2)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hduser/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/lib/python3/dist-packages (from statsmodels) (1.8.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/hduser/.local/lib/python3.10/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from vaderSentiment) (2.25.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m70.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas numpy matplotlib seaborn statsmodels vaderSentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76224b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the forecasted values to numpy arrays\n",
    "arima_forecast_1d = arima_forecast_1d.values\n",
    "arima_forecast_3d = arima_forecast_3d.values\n",
    "arima_forecast_7d = arima_forecast_7d.values\n",
    "\n",
    "sarima_forecast_1d = sarima_forecast_1d.values\n",
    "sarima_forecast_3d = sarima_forecast_3d.values\n",
    "sarima_forecast_7d = sarima_forecast_7d.values\n",
    "\n",
    "# Now you can plot these values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ARIMA\n",
    "plt.plot(range(1, 2), arima_forecast_1d, label='ARIMA 1 day')\n",
    "plt.plot(range(1, 4), arima_forecast_3d, label='ARIMA 3 days')\n",
    "plt.plot(range(1, 8), arima_forecast_7d, label='ARIMA 7 days')\n",
    "\n",
    "# SARIMA\n",
    "plt.plot(range(1, 2), sarima_forecast_1d, label='SARIMA 1 day')\n",
    "plt.plot(range(1, 4), sarima_forecast_3d, label='SARIMA 3 days')\n",
    "plt.plot(range(1, 8), sarima_forecast_7d, label='SARIMA 7 days')\n",
    "\n",
    "# RNN\n",
    "plt.plot(range(1, 2), rnn_forecast_1d, label='RNN 1 day')\n",
    "plt.plot(range(1, 4), rnn_forecast_3d, label='RNN 3 days')\n",
    "plt.plot(range(1, 8), rnn_forecast_7d, label='RNN 7 days')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Sentiment Forecast')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Average Sentiment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60c8a9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02c0af6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now you can plot these values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Actual sentiment\n",
    "plt.plot(range(len(actual_sentiment)-7, len(actual_sentiment)), actual_sentiment[-7:], label='Actual Sentiment')\n",
    "\n",
    "# ARIMA\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(arima_forecast_1d)), arima_forecast_1d, label='ARIMA 1 day')\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(arima_forecast_3d)), arima_forecast_3d, label='ARIMA 3 days')\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(arima_forecast_7d)), arima_forecast_7d, label='ARIMA 7 days')\n",
    "\n",
    "# SARIMA\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(sarima_forecast_1d)), sarima_forecast_1d, label='SARIMA 1 day')\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(sarima_forecast_3d)), sarima_forecast_3d, label='SARIMA 3 days')\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(sarima_forecast_7d)), sarima_forecast_7d, label='SARIMA 7 days')\n",
    "\n",
    "# RNN\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(rnn_forecast_1d)), rnn_forecast_1d, label='RNN 1 day')\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(rnn_forecast_3d)), rnn_forecast_3d, label='RNN 3 days')\n",
    "plt.plot(range(len(actual_sentiment), len(actual_sentiment)+len(rnn_forecast_7d)), rnn_forecast_7d, label='RNN 7 days')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Sentiment Forecast')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Average Sentiment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e6afa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab89f6",
   "metadata": {},
   "source": [
    "## Interactive dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07352ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7a304329b640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Initialize the app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout\n",
    "app.layout = html.Div([\n",
    "    html.H1('Sentiment Analysis Dashboard'),\n",
    "    dcc.Graph(\n",
    "        id='sentiment-graph',\n",
    "        figure={\n",
    "            'data': [\n",
    "                go.Scatter(x=list(range(len(actual_sentiment)-7, len(actual_sentiment))), y=actual_sentiment[-7:], mode='lines', name='Actual Sentiment'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(arima_forecast_1d))), y=arima_forecast_1d, mode='lines', name='ARIMA 1 day'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(arima_forecast_3d))), y=arima_forecast_3d, mode='lines', name='ARIMA 3 days'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(arima_forecast_7d))), y=arima_forecast_7d, mode='lines', name='ARIMA 7 days'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(sarima_forecast_1d))), y=sarima_forecast_1d, mode='lines', name='SARIMA 1 day'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(sarima_forecast_3d))), y=sarima_forecast_3d, mode='lines', name='SARIMA 3 days'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(sarima_forecast_7d))), y=sarima_forecast_7d, mode='lines', name='SARIMA 7 days'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(rnn_forecast_1d))), y=rnn_forecast_1d, mode='lines', name='RNN 1 day'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(rnn_forecast_3d))), y=rnn_forecast_3d, mode='lines', name='RNN 3 days'),\n",
    "                go.Scatter(x=list(range(len(actual_sentiment), len(actual_sentiment)+len(rnn_forecast_7d))), y=rnn_forecast_7d, mode='lines', name='RNN 7 days'),\n",
    "            ],\n",
    "            'layout': go.Layout(\n",
    "                title='Sentiment Over Time',\n",
    "                xaxis=dict(title='Days'),\n",
    "                yaxis=dict(title='Average Sentiment')\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874eca5",
   "metadata": {},
   "source": [
    "### MontoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ad08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymongo==3.12.3  \n",
    "\n",
    "# I had to install this version because The newest verion gave me lots of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "539a5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# My MongoDB connection details\n",
    "client = MongoClient(\"mongodb://localhost:27017/\") \n",
    "db = client[\"ProjectTweets\"]  # My data base name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a46bff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df5 = pd.read_csv('ProjectTweets.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30eb6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df5.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbd4b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db[\"my_collection\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc9b96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"my_database\"]\n",
    "collection = db[\"my_collection\"]\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('ProjectTweets.csv')\n",
    "\n",
    "# Convert to dictionaries\n",
    "data = df.to_dict(orient='records')\n",
    "\n",
    "# Insert into MongoDB\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(\"Data uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fd8cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('664eada25c8a34c9afff91d9'), '0': 1, '1467810369': 1467810672, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:49 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'scotthamilton', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91da'), '0': 2, '1467810369': 1467810917, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:53 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'mattycus', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds'}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91db'), '0': 3, '1467810369': 1467811184, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:57 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'ElleCTF', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": 'my whole body feels itchy and like its on fire '}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91dc'), '0': 4, '1467810369': 1467811193, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:57 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'Karoli', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91dd'), '0': 5, '1467810369': 1467811372, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:20:00 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'joy_wolf', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": '@Kwesidei not the whole crew '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:03:21 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 246844 ms exceeds timeout 120000 ms\n",
      "24/05/23 19:03:21 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/05/23 19:03:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:03:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:03:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:03:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:03:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:03:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:03:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:03:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:04:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:04:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:04:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:04:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:04:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:04:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:04:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:04:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:04:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:04:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:04:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:04:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:05:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:05:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:05:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:05:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:05:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:05:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:05:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:05:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:05:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:05:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:05:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:05:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:06:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:06:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:06:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:06:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:06:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:06:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/23 19:06:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:06:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:06:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:06:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:06:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:06:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:07:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:07:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:07:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:07:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:07:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:07:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:07:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:07:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:07:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:07:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:07:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:07:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:08:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:08:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:08:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:08:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:08:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:08:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:08:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:08:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:08:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:08:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:08:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:08:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:09:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:09:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:09:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:09:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:09:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:09:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:09:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:09:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:09:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:09:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:09:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:09:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:10:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:10:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:10:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:10:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:10:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:10:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:10:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:10:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:10:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:10:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:10:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:10:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:11:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:11:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:11:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:11:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:11:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:11:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:11:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:11:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:11:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:11:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:11:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:11:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:12:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:12:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:12:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:12:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:12:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:12:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:12:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:12:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:12:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:12:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:12:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:12:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:13:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:13:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 19:13:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:13:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.0.2.15:44243\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/23 19:13:16 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all documents\n",
    "all_documents = collection.find()\n",
    "\n",
    "# Display the first few rows\n",
    "for doc in all_documents.limit(5):\n",
    "    print(doc)\n",
    "    \n",
    "#Now we can see that mongoDB is working fine and is able to read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ea541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a21030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1711d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
