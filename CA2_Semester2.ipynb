{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75069842",
   "metadata": {},
   "source": [
    "Jesus Rodrigo Colina Nunez\n",
    "\n",
    "Student Number: 2017156 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbd3d4",
   "metadata": {},
   "source": [
    "CA 2 Semester 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa06a25",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee86c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, to_timestamp, date_format, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8341ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "##spark.conf.set(\"spark.sql.debug.maxToStringFields\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1030c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8986866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ProjectTweets.csv')\n",
    "\n",
    "#Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eff8a538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  5  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()\n",
    "\n",
    "# Hhere wI show how it looks, HERE I am not using Pyspark just yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a99ed975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').option('header', 'false').load('/user1/ProjectTweets.csv')\n",
    "\n",
    "#I load the data set into Pyspak in order to read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29760b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#More imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60e8544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.show()\n",
    "\n",
    "#Here I show the data set and we see that it does not have columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3474bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "\n",
    "#Inspect the DataFrame's Structure:  It reveals the blueprint of your data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046c0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"index\", \"id\", \"timestamp\", \"query\", \"username\", \"tweet\"]\n",
    "for i in range(len(df.columns)):\n",
    "    df = df.withColumnRenamed(\"_c\" + str(i), columns[i])\n",
    "    \n",
    "#I am going to change the name of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aadc40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff2a4061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "# This schema provides a valuable overview for understanding the structure and content of my dataset \n",
    "# before I start analyzing or manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca9b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|index|id        |timestamp                   |query   |username       |tweet                                                                                                              |\n",
      "+-----+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|1    |1467810672|Mon Apr 06 22:19:49 PDT 2009|NO_QUERY|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|2    |1467810917|Mon Apr 06 22:19:53 PDT 2009|NO_QUERY|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|3    |1467811184|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|ElleCTF        |my whole body feels itchy and like its on fire                                                                     |\n",
      "|4    |1467811193|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "|5    |1467811372|Mon Apr 06 22:20:00 PDT 2009|NO_QUERY|joy_wolf       |@Kwesidei not the whole crew                                                                                       |\n",
      "|6    |1467811592|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|mybirch        |Need a hug                                                                                                         |\n",
      "|7    |1467811594|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|coZZ           |@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                |\n",
      "|8    |1467811795|Mon Apr 06 22:20:05 PDT 2009|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope they didn't have it                                                                                |\n",
      "|9    |1467812025|Mon Apr 06 22:20:09 PDT 2009|NO_QUERY|mimismo        |@twittera que me muera ?                                                                                           |\n",
      "+-----+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)\n",
    "\n",
    "#Here I show the 10 first rows and we noticed that the names has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "944a47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+--------+--------------------+--------------------+\n",
      "|summary|             index|                  id|           timestamp|   query|            username|               tweet|\n",
      "+-------+------------------+--------------------+--------------------+--------+--------------------+--------------------+\n",
      "|  count|           1600000|             1600000|             1600000| 1600000|             1600000|             1600000|\n",
      "|   mean|          799999.5|1.9988175522956276E9|                null|    null| 4.325887521835714E9|                null|\n",
      "| stddev|461880.35968924535|1.9357607362268043E8|                null|    null|5.162733218454890...|                null|\n",
      "|    min|                 0|          1467810369|Fri Apr 17 20:30:...|NO_QUERY|        000catnap000|                 ...|\n",
      "|    max|            999999|          2329205794|Wed May 27 07:27:...|NO_QUERY|          zzzzeus111|ï¿½ï¿½ï¿½ï¿½ï¿½ß§...|\n",
      "+-------+------------------+--------------------+--------------------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Get summary statistics count, mean\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56ff2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     tweet_length|\n",
      "+-------+-----------------+\n",
      "|  count|          1600000|\n",
      "|   mean|     74.090110625|\n",
      "| stddev|36.44113790653486|\n",
      "|    min|                6|\n",
      "|    max|              374|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add a column for tweet length\n",
    "df = df.withColumn(\"tweet_length\", length(col(\"tweet\")))\n",
    "\n",
    "# Analyze tweet lengths (min, max, mean)\n",
    "df.describe(\"tweet_length\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b1de9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 01:25:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|day_of_week|tweet_count|\n",
      "+-----------+-----------+\n",
      "|     Sunday|     382894|\n",
      "|     Monday|     302830|\n",
      "|   Saturday|     300944|\n",
      "|    Tuesday|     226527|\n",
      "|     Friday|     170511|\n",
      "|  Wednesday|     120866|\n",
      "|   Thursday|      95428|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|hour|tweet_count|\n",
      "+----+-----------+\n",
      "|  00|      55720|\n",
      "|  01|      51843|\n",
      "|  02|      53485|\n",
      "|  03|      57722|\n",
      "|  04|      57059|\n",
      "|  05|      68964|\n",
      "|  06|      78328|\n",
      "|  07|      84750|\n",
      "|  08|      80865|\n",
      "|  09|      75268|\n",
      "|  10|      73991|\n",
      "|  11|      74253|\n",
      "|  12|      76995|\n",
      "|  13|      78623|\n",
      "|  14|      80852|\n",
      "|  15|      83654|\n",
      "|  16|      76287|\n",
      "|  17|      67278|\n",
      "|  18|      60689|\n",
      "|  19|      61009|\n",
      "+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, to_timestamp, date_format, length\n",
    "\n",
    "# Option 1: Set legacy parser globally (recommended for quick fix)\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"TwitterEDA\")\\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Convert timestamp to a datetime format\n",
    "df = df.withColumn(\"timestamp_dt\", to_timestamp(col(\"timestamp\"), \"EEE MMM dd HH:mm:ss zzz yyyy\")) Explicit format string\n",
    "\n",
    "\n",
    "# Extract day of week, hour, and date\n",
    "df = df.withColumn(\"day_of_week\", date_format(\"timestamp_dt\", \"EEEE\"))\\\n",
    "       .withColumn(\"hour\", date_format(\"timestamp_dt\", \"HH\"))\\\n",
    "       .withColumn(\"date\", date_format(\"timestamp_dt\", \"yyyy-MM-dd\"))\n",
    "\n",
    "# Count tweets by day of week and hour\n",
    "df.groupBy(\"day_of_week\").agg(count(\"*\").alias(\"tweet_count\")).orderBy(col(\"tweet_count\").desc()).show()\n",
    "df.groupBy(\"hour\").agg(count(\"*\").alias(\"tweet_count\")).orderBy(col(\"hour\")).show()\n",
    "\n",
    "# This tells Spark exactly how to interpret your timestamp string, ensuring consistent behavior \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04387bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a940a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8770a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2c8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3cc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c28098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a4fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bf554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad35a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba7ae16f",
   "metadata": {},
   "source": [
    "### MontoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ad08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymongo==3.12.3  # Example: Install PyMongo version 3.12.3\n",
    "\n",
    "# I had to install this version because The newest verion gave me lots of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5b80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "539a5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# My MongoDB connection details\n",
    "client = MongoClient(\"mongodb://localhost:27017/\") \n",
    "db = client[\"ProjectTweets\"]  # My data base name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a46bff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df5 = pd.read_csv('ProjectTweets.csv')  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30eb6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df5.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbd4b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db[\"my_collection\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc9b96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"my_database\"]\n",
    "collection = db[\"my_collection\"]\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('ProjectTweets.csv')\n",
    "\n",
    "# Convert to dictionaries\n",
    "data = df.to_dict(orient='records')\n",
    "\n",
    "# Insert into MongoDB\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(\"Data uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fd8cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('664eada25c8a34c9afff91d9'), '0': 1, '1467810369': 1467810672, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:49 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'scotthamilton', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91da'), '0': 2, '1467810369': 1467810917, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:53 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'mattycus', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds'}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91db'), '0': 3, '1467810369': 1467811184, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:57 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'ElleCTF', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": 'my whole body feels itchy and like its on fire '}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91dc'), '0': 4, '1467810369': 1467811193, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:19:57 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'Karoli', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"}\n",
      "{'_id': ObjectId('664eada25c8a34c9afff91dd'), '0': 5, '1467810369': 1467811372, 'Mon Apr 06 22:19:45 PDT 2009': 'Mon Apr 06 22:20:00 PDT 2009', 'NO_QUERY': 'NO_QUERY', '_TheSpecialOne_': 'joy_wolf', \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\": '@Kwesidei not the whole crew '}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all documents\n",
    "all_documents = collection.find()\n",
    "\n",
    "# Display the first few documents (e.g., the first 5)\n",
    "for doc in all_documents.limit(5):\n",
    "    print(doc)\n",
    "    \n",
    "#Now we can see that mongoDB is working fine and is able to read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ea541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a21030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1711d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
